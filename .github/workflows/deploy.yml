name: Deploy to Production

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  deploy:
    name: Deploy to Server
    runs-on: ubuntu-latest
    # PostgreSQL service for Prisma during build (uses ephemeral test DB)
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 5s
          --health-timeout 3s
          --health-retries 3
        ports:
          - 5432:5432
    env:
      HOST: ${{ secrets.HOST }}
      SSH_USER: ${{ secrets.SSH_USER }}
      SSH_KEY: ${{ secrets.SSH_KEY }}
      SSH_PORT: ${{ secrets.SSH_PORT }}
      NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET }}
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      NPM_REGISTRY: https://registry.npmjs.org/
      # API Keys for build and runtime
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
      GOOGLE_CLOUD_OCR_API_KEY: ${{ secrets.GOOGLE_CLOUD_OCR_API_KEY }}
      GOOGLE_CLOUD_API_KEY: ${{ secrets.GOOGLE_CLOUD_API_KEY }}
      # OAuth Credentials - CRITICAL: Must be defined here to be used in deployment
      GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
      GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
      GITHUB_ID: ${{ secrets.GITHUB_ID }}
      GITHUB_SECRET: ${{ secrets.GITHUB_SECRET }}
      # For CI Prisma generate step only (uses local postgres service)
      PRISMA_DATABASE_URL: "postgresql://postgres:postgres@localhost:5432/testdb"
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Cache npm
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-${{ runner.os }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            npm-${{ runner.os }}-

      - name: Cache prisma engines
        uses: actions/cache@v4
        with:
          path: ~/.cache/prisma
          key: prisma-${{ runner.os }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            prisma-${{ runner.os }}-

      - name: Configure npm (parallel optimizations)
        run: |
          npm config set registry "$NPM_REGISTRY"
          npm config set progress false
          npm config set audit false
          npm config set fund false
          npm config set maxsockets 100
          npm config set fetch-retries 2
          npm config set fetch-retry-mintimeout 2000
          npm config set fetch-retry-maxtimeout 60000

      - name: Install dependencies (faster CI)
        run: |
          npm ci --legacy-peer-deps --prefer-offline --no-audit --cache ~/.npm --fetch-timeout=60000 --fetch-retries=2 2>&1 | grep -E "^(added|up to date)" || true

      - name: Build (production optimized)
        env:
          NODE_ENV: production
          NEXTAUTH_SECRET: ${{ env.NEXTAUTH_SECRET }}
          NEXTAUTH_URL: https://naukrimili.com
          NEXT_PUBLIC_APP_URL: https://naukrimili.com
          DATABASE_URL: ${{ env.PRISMA_DATABASE_URL }}
          NEXT_TELEMETRY_DISABLED: 1
          SKIP_ENV_VALIDATION: 1
          NODE_OPTIONS: --max-old-space-size=4096
          SWC_NUM_THREADS: 4
          # API Keys available during build
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ env.GEMINI_API_KEY }}
          GROQ_API_KEY: ${{ env.GROQ_API_KEY }}
          GOOGLE_CLOUD_OCR_API_KEY: ${{ env.GOOGLE_CLOUD_OCR_API_KEY }}
          GOOGLE_CLOUD_API_KEY: ${{ env.GOOGLE_CLOUD_API_KEY }}
        run: |
           # Install PostgreSQL client tools if not available
           if ! command -v pg_isready &> /dev/null || ! command -v psql &> /dev/null; then
             echo "üì¶ Installing PostgreSQL client tools..."
             sudo apt-get update -qq && sudo apt-get install -y postgresql-client || {
               echo "‚ö†Ô∏è  Could not install postgresql-client, trying alternative..."
             }
           fi
           
           # Wait for Postgres to be ready (optimized - PostgreSQL health check makes this faster)
           echo "‚è≥ Waiting for PostgreSQL to be ready..."
           MAX_RETRIES=10
           RETRY_COUNT=0
           until pg_isready -h localhost -p 5432 -U postgres || [ $RETRY_COUNT -ge $MAX_RETRIES ]; do
             [ $RETRY_COUNT -eq 0 ] || echo "  Waiting for Postgres... (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)"
             sleep 0.5
             RETRY_COUNT=$((RETRY_COUNT + 1))
           done
           
           if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
             echo "‚ùå PostgreSQL failed to become ready after $MAX_RETRIES attempts"
             exit 1
           fi
           echo "‚úÖ PostgreSQL is ready"
         
           # Initialize database schema in CI (creates tables in testdb so build queries work)
           echo "üóÑÔ∏è Initializing CI database schema..."
           
           # CRITICAL: In CI, ALWAYS use the CI database (postgres:postgres@localhost:5432/testdb)
           # DO NOT use production DATABASE_URL from secrets in CI build steps
           export DATABASE_URL="$PRISMA_DATABASE_URL"
           echo "üìã Using CI DATABASE_URL: ${DATABASE_URL//:*@/:***@}" # Mask password
           echo "   CI Database: postgres:postgres@localhost:5432/testdb"
           
           # CRITICAL: Ensure we're not accidentally using production DATABASE_URL
           if echo "$DATABASE_URL" | grep -qv "postgres:postgres@localhost:5432/testdb"; then
             echo "‚ùå FATAL: DATABASE_URL does not match expected CI database"
             echo "   Expected: postgresql://postgres:postgres@localhost:5432/testdb"
             echo "   Got: ${DATABASE_URL:0:80}..."
             echo "   This means CI is trying to use production database - ABORTING"
             exit 1
           fi
           
           # Verify PostgreSQL service is accessible with CI credentials
           echo "üîç Verifying CI database connection..."
           if ! PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d testdb -c "SELECT version();" > /dev/null 2>&1; then
             echo "‚ùå FATAL: Cannot connect to CI database with postgres:postgres@localhost:5432/testdb"
             echo "   PostgreSQL service may not be ready yet"
             echo "   Verifying PostgreSQL service status..."
             pg_isready -h localhost -p 5432 || echo "   PostgreSQL is not ready"
             exit 1
           fi
           echo "‚úÖ CI database connection verified (using postgres user)"
           
           # CRITICAL: Initialize Prisma migrations table first (required for baseline)
           echo "üìã Initializing Prisma migrations table..."
           # Create migrations table manually if it doesn't exist
           PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d testdb -c "
             CREATE TABLE IF NOT EXISTS \"_prisma_migrations\" (
               \"id\" VARCHAR(36) PRIMARY KEY,
               \"checksum\" VARCHAR(64) NOT NULL,
               \"finished_at\" TIMESTAMP,
               \"migration_name\" VARCHAR(255) NOT NULL,
               \"logs\" TEXT,
               \"rolled_back_at\" TIMESTAMP,
               \"started_at\" TIMESTAMP NOT NULL DEFAULT NOW(),
               \"applied_steps_count\" INTEGER NOT NULL DEFAULT 0
             );
           " 2>/dev/null || {
             echo "‚ö†Ô∏è  Could not create migrations table (may already exist)"
           }
          
           # CRITICAL: Use db push FIRST to sync schema and create all tables
           # This ensures all tables exist before migrations try to reference them
           echo "üìã Syncing database schema (creates all tables from schema.prisma)..."
           # CRITICAL: Explicitly set DATABASE_URL for Prisma commands to ensure CI database is used
           if DATABASE_URL="$PRISMA_DATABASE_URL" npx prisma db push --schema=./prisma/schema.prisma --skip-generate --accept-data-loss; then
             echo "‚úÖ Schema synced successfully"
             
             # After db push, baseline migrations to mark them as applied
             # This prevents P3005 error (schema not empty)
             echo "üìã Baseling migrations (marking as applied since db push already created tables)..."
             
             # Get list of all migration folders
             MIGRATIONS=$(ls -d prisma/migrations/*/ 2>/dev/null | sort | sed 's|prisma/migrations/||' | sed 's|/$||' || true)
             
             if [ -n "$MIGRATIONS" ]; then
               # Check which migrations are already applied using Prisma (more reliable)
               echo "  Checking migration status via Prisma..."
               
               # CRITICAL: Use direct psql with CI credentials (most reliable)
               # Prisma migrate status may fail if DATABASE_URL is wrong, so use direct query first
               echo "  Checking applied migrations via direct database query (CI only)..."
               APPLIED_MIGRATIONS=$(PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d testdb -tAc "SELECT migration_name FROM _prisma_migrations WHERE finished_at IS NOT NULL ORDER BY finished_at;" 2>/dev/null || echo "")
               
               # Fallback: Use Prisma if direct query fails (shouldn't happen in CI)
               if [ -z "$APPLIED_MIGRATIONS" ]; then
                 echo "  Fallback: Using Prisma migrate status with explicit CI DATABASE_URL..."
                 APPLIED_MIGRATIONS=$(DATABASE_URL="$PRISMA_DATABASE_URL" timeout 15 npx prisma migrate status --schema=./prisma/schema.prisma 2>&1 | grep -E "^[0-9]+_[^ ]+$" | sed 's/.* //' || echo "")
               fi
               
               TOTAL=$(echo "$MIGRATIONS" | wc -l)
               COUNT=0
               MARKED=0
               SKIPPED=0
               
               for migration in $MIGRATIONS; do
                 COUNT=$((COUNT + 1))
                 echo "  [$COUNT/$TOTAL] Checking: $migration"
                 
                 # Check if already applied (fast check)
                 if [ -n "$APPLIED_MIGRATIONS" ] && echo "$APPLIED_MIGRATIONS" | grep -q "^$migration$" 2>/dev/null; then
                   echo "    ‚úÖ Already applied, skipping"
                   SKIPPED=$((SKIPPED + 1))
                   continue
                 fi
                 
                 # Mark as applied with timeout (3 seconds max per migration - faster)
                 echo "    Marking as applied..."
                 # CRITICAL: Explicitly set DATABASE_URL for Prisma to ensure CI database is used
                 if DATABASE_URL="$PRISMA_DATABASE_URL" timeout 3 npx prisma migrate resolve --applied "$migration" --schema=./prisma/schema.prisma 2>/dev/null; then
                   MARKED=$((MARKED + 1))
                   echo "    ‚úÖ Marked as applied"
                 else
                   echo "    ‚ö†Ô∏è  Could not mark (may already be applied or timeout)"
                 fi
               done
               echo "‚úÖ Baseline complete: $MARKED new migrations marked, $SKIPPED already applied, $TOTAL total"
             else
               echo "‚ö†Ô∏è  No migrations found to baseline"
             fi
           else
             echo "‚ö†Ô∏è  db push had warnings, but continuing..."
           fi
           
           # Try to run migrations anyway (they should be idempotent now)
           echo "üîÑ Running pending migrations (should be mostly no-op after baseline)..."
           # CRITICAL: Explicitly set DATABASE_URL for Prisma to ensure CI database is used
           timeout 30 DATABASE_URL="$PRISMA_DATABASE_URL" npx prisma migrate deploy --schema=./prisma/schema.prisma 2>&1 || {
             EXIT_CODE=$?
             if [ $EXIT_CODE -eq 124 ]; then
               echo "‚ö†Ô∏è  Migration deploy timed out (CI only, continuing anyway)"
             else
               echo "‚ö†Ô∏è  Migration deploy had warnings, but continuing (migrations are idempotent)..."
               # Log only first few lines of error to avoid spam
               echo "$(tail -5)" || true
             fi
           }
         
           # Generate Prisma client (doesn't need database, but ensure correct env)
           DATABASE_URL="$PRISMA_DATABASE_URL" npx prisma generate --skip-engine-check 2>/dev/null || DATABASE_URL="$PRISMA_DATABASE_URL" npx prisma generate
         
           # Build application
           npm run build

      - name: Optimize for production
        run: |
          # Keep only production node_modules (removes dev deps)
          npm prune --production --no-save
          # Remove unnecessary files from node_modules
          find node_modules -type d -name ".bin" -prune -o -type f \( -name "*.md" -o -name "*.ts" -o -name "*.map" \) -delete 2>/dev/null || true
          # Remove build cache
          rm -rf .next/cache .next/static/chunks/*.map 2>/dev/null || true

      - name: Create minimal deployment bundle
        run: |
          mkdir -p deploy && cd deploy
          cp -r ../.next .
          cp -r ../node_modules .
          cp ../package.json ../package-lock.json ../ecosystem.config.cjs ../next.config.mjs ../server.cjs .
          cp -r ../public ../prisma .
          # Include database initialization script (create scripts directory and copy script)
          mkdir -p scripts
          if [ -f ../scripts/init-database.sh ]; then
            cp ../scripts/init-database.sh scripts/
          fi
          cp ../.env.production . 2>/dev/null || true
          cd ..
          # Use zstd level 3 for fast compression/decompression (level 19 is too slow)
          tar -I 'zstd -3 --threads=0' -cf release.tar.zst deploy/
          rm -rf deploy
          ls -lh release.tar.zst

      - name: Upload artifact to server (zstd compression)
        uses: appleboy/scp-action@v0.1.5
        timeout-minutes: 10
        continue-on-error: false
        with:
          host: ${{ env.HOST }}
          username: ${{ env.SSH_USER }}
          key: ${{ env.SSH_KEY }}
          port: ${{ env.SSH_PORT }}
          source: "release.tar.zst"
          target: "/var/www/naukrimili"
          timeout: 300s
          strip_components: 0

      - name: Verify SSH connection
        run: |
          echo "üîç Testing SSH connection to ${{ env.HOST }}:${{ env.SSH_PORT }}..."
          
          # Setup SSH directory and known hosts
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keygen -R ${{ env.HOST }} 2>/dev/null || true
          ssh-keyscan -p ${{ env.SSH_PORT }} ${{ env.HOST }} >> ~/.ssh/known_hosts 2>/dev/null || true
          
          # Save SSH key to file with proper permissions
          SSH_KEY_FILE=$(mktemp)
          echo "${{ env.SSH_KEY }}" > "$SSH_KEY_FILE"
          chmod 600 "$SSH_KEY_FILE"
          
          # Test connection with retry
          MAX_ATTEMPTS=3
          ATTEMPT=1
          CONNECTION_SUCCESS=false
          
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "  Attempt $ATTEMPT/$MAX_ATTEMPTS..."
            if ssh -i "$SSH_KEY_FILE" \
                   -o StrictHostKeyChecking=no \
                   -o UserKnownHostsFile=~/.ssh/known_hosts \
                   -o ConnectTimeout=10 \
                   -o BatchMode=yes \
                   -p ${{ env.SSH_PORT }} \
                   ${{ env.SSH_USER }}@${{ env.HOST }} \
                   "echo 'SSH connection successful'" 2>&1; then
              echo "‚úÖ SSH connection verified"
              CONNECTION_SUCCESS=true
              break
            else
              if [ $ATTEMPT -lt $MAX_ATTEMPTS ]; then
                echo "  ‚ö†Ô∏è  Connection failed, retrying in 2 seconds..."
                sleep 2
              fi
            fi
            ATTEMPT=$((ATTEMPT + 1))
          done
          
          # Cleanup
          rm -f "$SSH_KEY_FILE"
          
          if [ "$CONNECTION_SUCCESS" != "true" ]; then
            echo "‚ùå SSH connection failed after $MAX_ATTEMPTS attempts"
            echo ""
            echo "üîß Troubleshooting:"
            echo "   1. Verify HOST secret is correct: ${{ env.HOST }}"
            echo "   2. Verify SSH_PORT secret is correct: ${{ env.SSH_PORT }}"
            echo "   3. Verify SSH_USER secret is correct: ${{ env.SSH_USER }}"
            echo "   4. Verify SSH_KEY secret contains the full private key (including BEGIN/END lines)"
            echo "   5. Ensure server firewall allows connections from GitHub Actions IPs"
            echo "   6. Test connection locally: ssh -p ${{ env.SSH_PORT }} ${{ env.SSH_USER }}@${{ env.HOST }}"
            exit 1
          fi
        continue-on-error: false

      - name: Deploy via SSH (optimized)
        uses: appleboy/ssh-action@v1.0.0
        timeout-minutes: 20
        env:
          NEXTAUTH_SECRET: ${{ env.NEXTAUTH_SECRET }}
          DATABASE_URL: ${{ env.DATABASE_URL }}
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ env.GEMINI_API_KEY }}
          GROQ_API_KEY: ${{ env.GROQ_API_KEY }}
          GOOGLE_CLOUD_OCR_API_KEY: ${{ env.GOOGLE_CLOUD_OCR_API_KEY }}
          GOOGLE_CLOUD_API_KEY: ${{ env.GOOGLE_CLOUD_API_KEY }}
          # OAuth Credentials
          GOOGLE_CLIENT_ID: ${{ env.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ env.GOOGLE_CLIENT_SECRET }}
          GITHUB_ID: ${{ env.GITHUB_ID }}
          GITHUB_SECRET: ${{ env.GITHUB_SECRET }}
        with:
          host: ${{ env.HOST }}
          username: ${{ env.SSH_USER }}
          key: ${{ env.SSH_KEY }}
          port: ${{ env.SSH_PORT }}
          timeout: 120s
          command_timeout: 15m
          envs: NEXTAUTH_SECRET,DATABASE_URL,OPENAI_API_KEY,GEMINI_API_KEY,GROQ_API_KEY,GOOGLE_CLOUD_OCR_API_KEY,GOOGLE_CLOUD_API_KEY,GOOGLE_CLIENT_ID,GOOGLE_CLIENT_SECRET,GITHUB_ID,GITHUB_SECRET
          script: |
            set -e
            cd /var/www/naukrimili
            
            echo "‚ö° Starting optimized deployment..."
            
            # Ensure zstd is installed on server
            if ! command -v zstd &> /dev/null; then
              echo "üì¶ Installing zstd on server..."
              if command -v apt-get &> /dev/null; then
                sudo apt-get update -qq && sudo apt-get install -y zstd
              elif command -v yum &> /dev/null; then
                sudo yum install -y zstd
              elif command -v apk &> /dev/null; then
                sudo apk add zstd
              else
                echo "‚ö†Ô∏è  Could not install zstd automatically. Please install it manually."
              fi
            fi
            
            # Extract deployment bundle
            echo "üì¶ Extracting deployment bundle..."
            if command -v zstd &> /dev/null; then
              tar -I 'zstd -d --threads=0' -xf release.tar.zst 2>&1 | grep -E "(deploy/|extracting)" | head -20 || \
              { echo "‚ö†Ô∏è Extraction taking longer than expected, continuing..."; tar -I 'zstd -d --threads=0' -xf release.tar.zst; }
            else
              echo "‚ùå zstd not found. Cannot extract bundle."
              exit 1
            fi
            
            # Move to production location
            echo "üöÄ Installing new version..."
            rm -rf .next node_modules
            mv deploy/.next deploy/node_modules deploy/package.json deploy/ecosystem.config.cjs \
               deploy/next.config.mjs deploy/server.cjs deploy/prisma deploy/public . 2>/dev/null || true
            # Copy scripts directory if it exists
            if [ -d "deploy/scripts" ]; then
              mkdir -p scripts
              cp -r deploy/scripts/* scripts/ 2>/dev/null || true
            fi
            
            # Cleanup
            rm -rf deploy release.tar.zst .next.backup
            
            # Set environment
            export NODE_ENV=production
            export NEXTAUTH_SECRET="$NEXTAUTH_SECRET"
            export NEXTAUTH_URL="https://naukrimili.com"
            export NEXT_PUBLIC_APP_URL="https://naukrimili.com"
            export DATABASE_URL="$DATABASE_URL"
            export NEXT_TELEMETRY_DISABLED=1
            # API Keys for runtime
            export OPENAI_API_KEY="$OPENAI_API_KEY"
            export GEMINI_API_KEY="$GEMINI_API_KEY"
            export GROQ_API_KEY="$GROQ_API_KEY"
            export GOOGLE_CLOUD_OCR_API_KEY="$GOOGLE_CLOUD_OCR_API_KEY"
            export GOOGLE_CLOUD_API_KEY="$GOOGLE_CLOUD_API_KEY"
            # OAuth Credentials for Google/GitHub Sign-in
            export GOOGLE_CLIENT_ID="$GOOGLE_CLIENT_ID"
            export GOOGLE_CLIENT_SECRET="$GOOGLE_CLIENT_SECRET"
            export GITHUB_ID="$GITHUB_ID"
            export GITHUB_SECRET="$GITHUB_SECRET"
            
            # CRITICAL: Persist OAuth credentials to .env file for ecosystem.config.cjs
            echo "üìù Updating .env file with OAuth credentials..."
            if [ -f .env ]; then
              # Remove existing OAuth credentials if present
              sed -i '/^GOOGLE_CLIENT_ID=/d' .env
              sed -i '/^GOOGLE_CLIENT_SECRET=/d' .env
              sed -i '/^GITHUB_ID=/d' .env
              sed -i '/^GITHUB_SECRET=/d' .env
            else
              touch .env
            fi
            # Append OAuth credentials to .env file
            echo "GOOGLE_CLIENT_ID=$GOOGLE_CLIENT_ID" >> .env
            echo "GOOGLE_CLIENT_SECRET=$GOOGLE_CLIENT_SECRET" >> .env
            echo "GITHUB_ID=$GITHUB_ID" >> .env
            echo "GITHUB_SECRET=$GITHUB_SECRET" >> .env
            echo "‚úÖ OAuth credentials written to .env file"
            
            # Verify DATABASE_URL is set
            if [ -z "$DATABASE_URL" ]; then
              echo "‚ùå FATAL: DATABASE_URL environment variable is not set"
              echo "   Please ensure DATABASE_URL secret is configured in GitHub Actions"
              exit 1
            fi
            
            # Validate DATABASE_URL format
            if ! echo "$DATABASE_URL" | grep -qE "^postgresql://|^postgres://"; then
              echo "‚ùå FATAL: Invalid DATABASE_URL format"
              echo "   Expected format: postgresql://user:password@host:port/database"
              echo "   Got: ${DATABASE_URL:0:50}..."
              exit 1
            fi
            
            # Initialize database (create user and database if needed)
            echo "üóÑÔ∏è Initializing database..."
            if [ -f "scripts/init-database.sh" ]; then
              chmod +x scripts/init-database.sh
              # Export DATABASE_URL for the script
              export DATABASE_URL="$DATABASE_URL"
              
              # Run init script - exit on failure for remote databases (connection test)
              if ! bash scripts/init-database.sh; then
                EXIT_CODE=$?
                echo ""
                echo "‚ùå Database initialization failed with exit code: $EXIT_CODE"
                echo ""
                echo "üîç Possible causes:"
                echo "   1. Database user does not exist in remote database"
                echo "   2. Database does not exist"
                echo "   3. Incorrect credentials in DATABASE_URL"
                echo "   4. Database server is not accessible"
                echo ""
                echo "üìã To fix:"
                echo "   ================================================================="
                echo "   üîß MANUAL FIX REQUIRED"
                echo "   ================================================================="
                echo ""
                echo "   The database user specified in DATABASE_URL does not exist."
                echo ""
                echo "   Extract from DATABASE_URL: ${DATABASE_URL//:*@/:***@}"
                echo ""
                echo "   Connect to your PostgreSQL database as superuser and run:"
                echo ""
                echo "   CREATE ROLE <username> WITH LOGIN PASSWORD '<password>';"
                echo "   CREATE DATABASE <database> OWNER <username>;"
                echo "   GRANT ALL PRIVILEGES ON DATABASE <database> TO <username>;"
                echo "   \\c <database>"
                echo "   GRANT ALL ON SCHEMA public TO <username>;"
                echo ""
                echo "   Replace <username>, <password>, and <database> with actual values"
                echo "   from your DATABASE_URL secret."
                echo ""
                echo "   ================================================================="
                exit $EXIT_CODE
              fi
            else
              echo "‚ö†Ô∏è  Database initialization script not found, skipping user/database creation"
              echo "   Ensure database user and database exist before running migrations"
            fi
            
            # Run database migrations (critical - creates tables)
            echo "üîÑ Running database migrations..."
            if [ -d "prisma" ]; then
              # CRITICAL: Ensure DATABASE_URL is exported for Prisma
              # Add connection timeout parameters to fail fast if connection issues
              # This prevents Prisma from retrying for too long when user doesn't exist
              ENHANCED_DATABASE_URL="$DATABASE_URL"
              if echo "$ENHANCED_DATABASE_URL" | grep -qv "connect_timeout"; then
                SEPARATOR=$([ "${ENHANCED_DATABASE_URL#*?}" != "$ENHANCED_DATABASE_URL" ] && echo "&" || echo "?")
                ENHANCED_DATABASE_URL="${ENHANCED_DATABASE_URL}${SEPARATOR}connect_timeout=5&pool_timeout=5"
              fi
              export DATABASE_URL="$ENHANCED_DATABASE_URL"
              echo "üìã Using DATABASE_URL: ${DATABASE_URL//:*@/:***@}" # Mask password
              
              # Generate Prisma client first
              echo "  Generating Prisma client..."
              npx prisma generate --schema=./prisma/schema.prisma || {
                echo "‚ö†Ô∏è  Prisma generate failed, but continuing..."
              }
              
              # CRITICAL: Test database connection BEFORE attempting migrations
              # This fails fast if user/database doesn't exist, preventing long retries
              echo "  Testing database connection..."
              if ! timeout 10 npx prisma db execute --stdin --schema=./prisma/schema.prisma <<< "SELECT 1;" > /dev/null 2>&1; then
                echo "‚ùå Database connection test FAILED!"
                echo "   This likely means the database user or database does not exist"
                echo "   The init-database.sh script should have created them, but it may have failed"
                echo ""
                echo "   Please verify:"
                echo "   1. Database user exists in the database"
                echo "   2. Database exists"
                echo "   3. Credentials in DATABASE_URL are correct"
                exit 1
              fi
              echo "  ‚úÖ Database connection test passed"
              
              # CRITICAL: In production, we DON'T use --accept-data-loss to protect data
              # Only run migrations (which are idempotent and safe)
              echo "üìã Running database migrations (production-safe, no data loss)..."
              
              # Run migrations only (safe, idempotent, no data loss)
              # Prisma will automatically create _prisma_migrations table if it doesn't exist
              echo "  Running migrations (Prisma will handle table creation)..."
              
              # Check migration status first to identify conflicts (with faster timeout)
              echo "  Checking migration status..."
              MIGRATION_STATUS=$(timeout 10 npx prisma migrate status --schema=./prisma/schema.prisma 2>&1 || echo "status_failed")
              
              # Try to run migrations (with faster timeout to fail fast on connection issues)
              # Set Prisma connection timeout to 5 seconds (fail fast)
              export PRISMA_CLI_QUERY_ENGINE_TYPE=binary
              if timeout 45 npx prisma migrate deploy --schema=./prisma/schema.prisma 2>&1 | tee /tmp/migration.log; then
                echo "‚úÖ Migrations deployed successfully"
              else
                EXIT_CODE=$?
                MIGRATION_OUTPUT=$(cat /tmp/migration.log)
                
                if [ $EXIT_CODE -eq 124 ]; then
                  echo "‚ö†Ô∏è  Migration deploy timed out after 2 minutes"
                  echo "   This may indicate a slow database connection"
                  echo "   Checking migration status..."
                  echo "$MIGRATION_OUTPUT" | tail -20
                elif echo "$MIGRATION_OUTPUT" | grep -q "relation.*already exists\|P3018\|42P07"; then
                  # Migration conflict: table already exists
                  echo "‚ö†Ô∏è  Migration conflict detected: Table already exists"
                  echo "$MIGRATION_OUTPUT" | grep -E "relation|already exists|P3018" | head -5
                  
                  # Extract migration name from error
                  CONFLICT_MIGRATION=$(echo "$MIGRATION_OUTPUT" | grep -oP "migration '[^']+'" | head -1 | sed "s/migration '//; s/'//" || echo "")
                  
                  if [ -n "$CONFLICT_MIGRATION" ]; then
                    echo "  Resolving conflict by marking migration as applied: $CONFLICT_MIGRATION"
                    if timeout 15 npx prisma migrate resolve --applied "$CONFLICT_MIGRATION" --schema=./prisma/schema.prisma 2>&1; then
                      echo "  ‚úÖ Migration marked as applied, retrying deployment..."
                      # Retry migration deploy after resolving conflict
                      if timeout 60 npx prisma migrate deploy --schema=./prisma/schema.prisma 2>&1 | tee /tmp/migration-retry.log; then
                        echo "‚úÖ Migrations deployed successfully after conflict resolution"
                      else
                        echo "‚ùå Migration deploy still failed after conflict resolution:"
                        cat /tmp/migration-retry.log | tail -20
                        echo ""
                        echo "üîç Manual intervention may be required"
                        echo "   Run: npx prisma migrate resolve --applied $CONFLICT_MIGRATION"
                        exit 1
                      fi
                    else
                      echo "  ‚ö†Ô∏è  Could not resolve migration conflict automatically"
                      echo "   Please resolve manually: npx prisma migrate resolve --applied $CONFLICT_MIGRATION"
                      exit 1
                    fi
                  else
                    echo "  ‚ö†Ô∏è  Could not identify conflicting migration from error output"
                    echo "   Error details:"
                    echo "$MIGRATION_OUTPUT" | tail -30
                    exit 1
                  fi
                elif echo "$MIGRATION_OUTPUT" | grep -qi "FATAL.*role.*does not exist\|does not exist.*role"; then
                  echo "‚ùå Database role/user does not exist!"
                  echo "   Error details:"
                  echo "$MIGRATION_OUTPUT" | grep -i "FATAL\|role\|does not exist" | head -5
                  echo ""
                  echo "üîç Root Cause: The database user specified in DATABASE_URL does not exist"
                  echo ""
                  echo "üìã Solution:"
                  echo "   1. Connect to your PostgreSQL database as superuser"
                  echo "   2. Extract user from DATABASE_URL: ${DATABASE_URL//:*@/:***@}"
                  echo "   3. Create the user: CREATE ROLE <username> WITH LOGIN PASSWORD '<password>';"
                  echo "   4. Create the database: CREATE DATABASE <database> OWNER <username>;"
                  echo "   5. Grant privileges: GRANT ALL PRIVILEGES ON DATABASE <database> TO <username>;"
                  echo ""
                  echo "   Note: The init-database.sh script should have created the user"
                  echo "   but it may have failed silently for remote databases."
                  exit 1
                else
                  echo "‚ùå Migration deploy failed. Error details:"
                  echo "$MIGRATION_OUTPUT" | tail -30
                  echo ""
                  echo "üîç Troubleshooting:"
                  echo "   1. Check if DATABASE_URL is correct"
                  echo "   2. Verify database user exists and has permissions"
                  echo "   3. Ensure database server is accessible"
                  echo "   4. Check database connection from server"
                  exit 1
                fi
              fi
              echo "‚úÖ Database migrations complete"
            else
              echo "‚ö†Ô∏è No prisma directory found, skipping migrations"
            fi
            
            # Zero-downtime deployment using PM2 graceful reload
            echo "üîÑ Performing zero-downtime deployment..."
            mkdir -p ./logs
            
            # Check if process exists
            if pm2 list | grep -q "naukrimili"; then
              echo "  Process exists - using graceful reload (zero-downtime)..."
              # Use reload which starts new workers before killing old ones
              # This ensures zero-downtime: old process keeps serving while new one starts
              pm2 reload naukrimili --update-env --wait-ready
              
              # Wait for new process to be ready (old process still serving during this time)
              echo "  Waiting for new instance to be ready..."
              READY=false
              for i in {1..20}; do
                if curl -sf --max-time 2 http://localhost:3000/api/health > /dev/null 2>&1; then
                  # Double-check the process is actually responding
                  if pm2 list | grep -q "naukrimili.*online"; then
                    READY=true
                    echo "  ‚úÖ New instance is healthy and responding"
                    break
                  fi
                fi
                [ $i -lt 20 ] && sleep 1
              done
              
              if [ "$READY" = true ]; then
                echo "‚úÖ Zero-downtime deployment successful"
                pm2 save
                echo "‚úÖ Deployment complete in ~$(echo $SECONDS)s"
                exit 0
              else
                echo "‚ö†Ô∏è New instance health check failed, but old instance may still be serving"
                echo "  Checking process status..."
                pm2 status
                echo "‚ö†Ô∏è Deployment completed but health check timed out"
                echo "  Old process should still be serving requests"
                pm2 save
                exit 0
              fi
            else
              echo "  Process doesn't exist - starting fresh..."
              # First time deployment or process was stopped
              pm2 start ecosystem.config.cjs --env production --update-env
              
              # Wait for initial startup
              echo "  Waiting for app to start..."
              READY=false
              for i in {1..30}; do
                if curl -sf --max-time 2 http://localhost:3000/api/health > /dev/null 2>&1; then
                  if pm2 list | grep -q "naukrimili.*online"; then
                    READY=true
                    echo "  ‚úÖ App started successfully"
                    break
                  fi
                fi
                [ $i -lt 30 ] && sleep 1
              done
              
              if [ "$READY" = true ]; then
                echo "‚úÖ Deployment successful"
                pm2 save
                echo "‚úÖ Deployment complete in ~$(echo $SECONDS)s"
                exit 0
              else
                echo "‚ùå App failed to start within 60 seconds"
                echo "  Process status:"
                pm2 status
                echo "  Recent logs:"
                pm2 logs naukrimili --lines 20 --nostream
                exit 1
              fi
            fi
