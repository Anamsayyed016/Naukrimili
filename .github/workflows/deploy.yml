name: Deploy to Production

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  deploy:
    name: Deploy to Server
    runs-on: ubuntu-latest
    # PostgreSQL service for Prisma during build (uses ephemeral test DB)
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 5s
          --health-timeout 3s
          --health-retries 3
        ports:
          - 5432:5432
    env:
      HOST: ${{ secrets.HOST }}
      SSH_USER: ${{ secrets.SSH_USER }}
      SSH_KEY: ${{ secrets.SSH_KEY }}
      SSH_PORT: ${{ secrets.SSH_PORT }}
      NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET }}
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      NPM_REGISTRY: https://registry.npmjs.org/
      # API Keys for build and runtime
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
      GOOGLE_CLOUD_OCR_API_KEY: ${{ secrets.GOOGLE_CLOUD_OCR_API_KEY }}
      GOOGLE_CLOUD_API_KEY: ${{ secrets.GOOGLE_CLOUD_API_KEY }}
      # OAuth Credentials - CRITICAL: Must be defined here to be used in deployment
      GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
      GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
      GITHUB_ID: ${{ secrets.GITHUB_ID }}
      GITHUB_SECRET: ${{ secrets.GITHUB_SECRET }}
      # For CI Prisma generate step only (uses local postgres service)
      PRISMA_DATABASE_URL: "postgresql://postgres:postgres@localhost:5432/testdb"
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Cache npm
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-${{ runner.os }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            npm-${{ runner.os }}-

      - name: Cache prisma engines
        uses: actions/cache@v4
        with:
          path: ~/.cache/prisma
          key: prisma-${{ runner.os }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            prisma-${{ runner.os }}-

      - name: Configure npm (parallel optimizations)
        run: |
          npm config set registry "$NPM_REGISTRY"
          npm config set progress false
          npm config set audit false
          npm config set fund false
          npm config set maxsockets 100
          npm config set fetch-retries 2
          npm config set fetch-retry-mintimeout 2000
          npm config set fetch-retry-maxtimeout 60000

      - name: Install dependencies (faster CI)
        run: |
          npm ci --legacy-peer-deps --prefer-offline --no-audit --cache ~/.npm --fetch-timeout=60000 --fetch-retries=2 2>&1 | grep -E "^(added|up to date)" || true

      - name: Build (production optimized)
        env:
          NODE_ENV: production
          NEXTAUTH_SECRET: ${{ env.NEXTAUTH_SECRET }}
          NEXTAUTH_URL: https://naukrimili.com
          NEXT_PUBLIC_APP_URL: https://naukrimili.com
          DATABASE_URL: ${{ env.PRISMA_DATABASE_URL }}
          NEXT_TELEMETRY_DISABLED: 1
          SKIP_ENV_VALIDATION: 1
          NODE_OPTIONS: --max-old-space-size=4096
          SWC_NUM_THREADS: 4
          # API Keys available during build
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ env.GEMINI_API_KEY }}
          GROQ_API_KEY: ${{ env.GROQ_API_KEY }}
          GOOGLE_CLOUD_OCR_API_KEY: ${{ env.GOOGLE_CLOUD_OCR_API_KEY }}
          GOOGLE_CLOUD_API_KEY: ${{ env.GOOGLE_CLOUD_API_KEY }}
        run: |
           # Install PostgreSQL client tools if not available
           if ! command -v pg_isready &> /dev/null || ! command -v psql &> /dev/null; then
             echo "üì¶ Installing PostgreSQL client tools..."
             sudo apt-get update -qq && sudo apt-get install -y postgresql-client || {
               echo "‚ö†Ô∏è  Could not install postgresql-client, trying alternative..."
             }
           fi
           
           # Wait for Postgres to be ready (optimized - PostgreSQL health check makes this faster)
           echo "‚è≥ Waiting for PostgreSQL to be ready..."
           MAX_RETRIES=10
           RETRY_COUNT=0
           until pg_isready -h localhost -p 5432 -U postgres || [ $RETRY_COUNT -ge $MAX_RETRIES ]; do
             [ $RETRY_COUNT -eq 0 ] || echo "  Waiting for Postgres... (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)"
             sleep 0.5
             RETRY_COUNT=$((RETRY_COUNT + 1))
           done
           
           if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
             echo "‚ùå PostgreSQL failed to become ready after $MAX_RETRIES attempts"
             exit 1
           fi
           echo "‚úÖ PostgreSQL is ready"
         
           # Initialize database schema in CI (creates tables in testdb so build queries work)
           echo "üóÑÔ∏è Initializing CI database schema..."
           
           # CRITICAL: In CI, ALWAYS use the CI database (postgres:postgres@localhost:5432/testdb)
           # DO NOT use production DATABASE_URL from secrets in CI build steps
           export DATABASE_URL="$PRISMA_DATABASE_URL"
           echo "üìã Using CI DATABASE_URL: ${DATABASE_URL//:*@/:***@}" # Mask password
           echo "   CI Database: postgres:postgres@localhost:5432/testdb"
           
           # CRITICAL: Ensure we're not accidentally using production DATABASE_URL
           if echo "$DATABASE_URL" | grep -qv "postgres:postgres@localhost:5432/testdb"; then
             echo "‚ùå FATAL: DATABASE_URL does not match expected CI database"
             echo "   Expected: postgresql://postgres:postgres@localhost:5432/testdb"
             echo "   Got: ${DATABASE_URL:0:80}..."
             echo "   This means CI is trying to use production database - ABORTING"
             exit 1
           fi
           
           # CRITICAL: Ensure postgres user exists and has proper permissions
           echo "üîß Ensuring CI database user exists and has correct password..."
           # The postgres user should exist from the service, but ensure password is correct
           # Try to connect first - if this fails, the user might not exist or password is wrong
           if ! PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d postgres -c "SELECT version();" > /dev/null 2>&1; then
             echo "‚ö†Ô∏è  Cannot connect as postgres user, attempting to create/fix..."
             # Try to create postgres user if it doesn't exist (shouldn't happen, but verify)
             sudo -u postgres psql -c "DO \$\$ BEGIN IF NOT EXISTS (SELECT FROM pg_roles WHERE rolname='postgres') THEN CREATE ROLE postgres WITH LOGIN SUPERUSER PASSWORD 'postgres'; END IF; END \$\$;" 2>/dev/null || \
             psql -h localhost -U postgres -d postgres -c "DO \$\$ BEGIN IF NOT EXISTS (SELECT FROM pg_roles WHERE rolname='postgres') THEN CREATE ROLE postgres WITH LOGIN SUPERUSER PASSWORD 'postgres'; END IF; END \$\$;" 2>/dev/null || \
             psql -U postgres -d postgres -c "DO \$\$ BEGIN IF NOT EXISTS (SELECT FROM pg_roles WHERE rolname='postgres') THEN CREATE ROLE postgres WITH LOGIN SUPERUSER PASSWORD 'postgres'; END IF; END \$\$;" 2>/dev/null || true
             
             # Ensure password is correct
             sudo -u postgres psql -c "ALTER ROLE postgres WITH PASSWORD 'postgres';" 2>/dev/null || \
             psql -h localhost -U postgres -d postgres -c "ALTER ROLE postgres WITH PASSWORD 'postgres';" 2>/dev/null || true
           fi
           
           echo "‚úÖ Postgres user verified/created"
           
           # Verify PostgreSQL service is accessible with CI credentials
           echo "üîç Verifying CI database connection..."
           if ! PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d postgres -c "SELECT version();" > /dev/null 2>&1; then
             echo "‚ùå FATAL: Cannot connect to CI database with postgres user"
             echo "   Attempting to create/fix postgres user..."
             
             # Try to fix postgres user (if we can connect as any user)
             # First, check if we can connect without password (peer auth)
             sudo -u postgres psql -c "ALTER ROLE postgres WITH LOGIN PASSWORD 'postgres';" 2>/dev/null || \
             psql -h localhost -U postgres -d postgres -c "ALTER ROLE postgres WITH LOGIN PASSWORD 'postgres';" 2>/dev/null || true
             
             # Retry connection
             if ! PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d postgres -c "SELECT version();" > /dev/null 2>&1; then
               echo "‚ùå FATAL: Cannot connect to CI database with postgres:postgres@localhost:5432/testdb"
               echo "   PostgreSQL service may not be ready yet"
               echo "   Verifying PostgreSQL service status..."
               pg_isready -h localhost -p 5432 || echo "   PostgreSQL is not ready"
               exit 1
             fi
           fi
           
           # Ensure testdb database exists
           echo "üîß Ensuring CI test database exists..."
           PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d postgres -c "SELECT 1 FROM pg_database WHERE datname='testdb'" | grep -q 1 || \
           PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d postgres -c "CREATE DATABASE testdb OWNER postgres;" 2>/dev/null || true
           
           echo "‚úÖ CI database connection verified (using postgres user)"
           echo "‚úÖ CI database connection verified (using postgres user)"
           
           # Simplified CI schema sync and baseline
           echo "üìã Syncing CI database schema..."
           DATABASE_URL="$PRISMA_DATABASE_URL" npx prisma db push --schema=./prisma/schema.prisma --skip-generate --accept-data-loss 2>&1 | grep -E "(Pushed|Error)" || true
           
           # Baseline migrations (mark all as applied since db push created tables)
           echo "üìã Baseling migrations..."
           MIGRATIONS=$(ls -d prisma/migrations/*/ 2>/dev/null | sort | sed 's|prisma/migrations/||' | sed 's|/$||' || echo "")
           if [ -n "$MIGRATIONS" ]; then
             APPLIED=$(PGPASSWORD=postgres psql -h localhost -p 5432 -U postgres -d testdb -tAc "SELECT migration_name FROM _prisma_migrations WHERE finished_at IS NOT NULL;" 2>/dev/null || echo "")
             for migration in $MIGRATIONS; do
               if ! echo "$APPLIED" | grep -q "^$migration$" 2>/dev/null; then
                 DATABASE_URL="$PRISMA_DATABASE_URL" timeout 3 npx prisma migrate resolve --applied "$migration" --schema=./prisma/schema.prisma 2>/dev/null || true
               fi
             done
           fi
           
           # Run migrations (should be mostly no-op)
           DATABASE_URL="$PRISMA_DATABASE_URL" timeout 20 npx prisma migrate deploy --schema=./prisma/schema.prisma 2>&1 | grep -E "(migrated|Error)" || true
         
           # Generate Prisma client (doesn't need database, but ensure correct env)
           DATABASE_URL="$PRISMA_DATABASE_URL" npx prisma generate --skip-engine-check 2>/dev/null || DATABASE_URL="$PRISMA_DATABASE_URL" npx prisma generate
         
           # Build application
           npm run build

      - name: Optimize for production
        run: |
          # Keep only production node_modules (removes dev deps)
          npm prune --production --no-save
          # Remove unnecessary files from node_modules
          find node_modules -type d -name ".bin" -prune -o -type f \( -name "*.md" -o -name "*.ts" -o -name "*.map" \) -delete 2>/dev/null || true
          # Remove build cache
          rm -rf .next/cache .next/static/chunks/*.map 2>/dev/null || true

      - name: Create minimal deployment bundle
        run: |
          mkdir -p deploy && cd deploy
          cp -r ../.next .
          cp -r ../node_modules .
          cp ../package.json ../package-lock.json ../ecosystem.config.cjs ../next.config.mjs ../server.cjs .
          cp -r ../public ../prisma .
          # Include database initialization script (create scripts directory and copy script)
          mkdir -p scripts
          if [ -f ../scripts/init-database.sh ]; then
            cp ../scripts/init-database.sh scripts/
          fi
          cp ../.env.production . 2>/dev/null || true
          cd ..
          # Use zstd level 3 for fast compression/decompression (level 19 is too slow)
          tar -I 'zstd -3 --threads=0' -cf release.tar.zst deploy/
          rm -rf deploy
          ls -lh release.tar.zst

      - name: Upload artifact to server (zstd compression)
        uses: appleboy/scp-action@v0.1.5
        timeout-minutes: 10
        continue-on-error: false
        with:
          host: ${{ env.HOST }}
          username: ${{ env.SSH_USER }}
          key: ${{ env.SSH_KEY }}
          port: ${{ env.SSH_PORT }}
          source: "release.tar.zst"
          target: "/var/www/naukrimili"
          timeout: 300s
          strip_components: 0

      - name: Verify SSH connection
        run: |
          echo "üîç Testing SSH connection to ${{ env.HOST }}:${{ env.SSH_PORT }}..."
          
          # Setup SSH directory and known hosts
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keygen -R ${{ env.HOST }} 2>/dev/null || true
          ssh-keyscan -p ${{ env.SSH_PORT }} ${{ env.HOST }} >> ~/.ssh/known_hosts 2>/dev/null || true
          
          # Save SSH key to file with proper permissions
          SSH_KEY_FILE=$(mktemp)
          echo "${{ env.SSH_KEY }}" > "$SSH_KEY_FILE"
          chmod 600 "$SSH_KEY_FILE"
          
          # Test connection with retry
          MAX_ATTEMPTS=3
          ATTEMPT=1
          CONNECTION_SUCCESS=false
          
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "  Attempt $ATTEMPT/$MAX_ATTEMPTS..."
            if ssh -i "$SSH_KEY_FILE" \
                   -o StrictHostKeyChecking=no \
                   -o UserKnownHostsFile=~/.ssh/known_hosts \
                   -o ConnectTimeout=10 \
                   -o BatchMode=yes \
                   -p ${{ env.SSH_PORT }} \
                   ${{ env.SSH_USER }}@${{ env.HOST }} \
                   "echo 'SSH connection successful'" 2>&1; then
              echo "‚úÖ SSH connection verified"
              CONNECTION_SUCCESS=true
              break
            else
              if [ $ATTEMPT -lt $MAX_ATTEMPTS ]; then
                echo "  ‚ö†Ô∏è  Connection failed, retrying in 2 seconds..."
                sleep 2
              fi
            fi
            ATTEMPT=$((ATTEMPT + 1))
          done
          
          # Cleanup
          rm -f "$SSH_KEY_FILE"
          
          if [ "$CONNECTION_SUCCESS" != "true" ]; then
            echo "‚ùå SSH connection failed after $MAX_ATTEMPTS attempts"
            echo ""
            echo "üîß Troubleshooting:"
            echo "   1. Verify HOST secret is correct: ${{ env.HOST }}"
            echo "   2. Verify SSH_PORT secret is correct: ${{ env.SSH_PORT }}"
            echo "   3. Verify SSH_USER secret is correct: ${{ env.SSH_USER }}"
            echo "   4. Verify SSH_KEY secret contains the full private key (including BEGIN/END lines)"
            echo "   5. Ensure server firewall allows connections from GitHub Actions IPs"
            echo "   6. Test connection locally: ssh -p ${{ env.SSH_PORT }} ${{ env.SSH_USER }}@${{ env.HOST }}"
            exit 1
          fi
        continue-on-error: false

      - name: Deploy via SSH (optimized)
        uses: appleboy/ssh-action@v1.0.0
        timeout-minutes: 20
        env:
          NEXTAUTH_SECRET: ${{ env.NEXTAUTH_SECRET }}
          DATABASE_URL: ${{ env.DATABASE_URL }}
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ env.GEMINI_API_KEY }}
          GROQ_API_KEY: ${{ env.GROQ_API_KEY }}
          GOOGLE_CLOUD_OCR_API_KEY: ${{ env.GOOGLE_CLOUD_OCR_API_KEY }}
          GOOGLE_CLOUD_API_KEY: ${{ env.GOOGLE_CLOUD_API_KEY }}
          # OAuth Credentials
          GOOGLE_CLIENT_ID: ${{ env.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ env.GOOGLE_CLIENT_SECRET }}
          GITHUB_ID: ${{ env.GITHUB_ID }}
          GITHUB_SECRET: ${{ env.GITHUB_SECRET }}
        with:
          host: ${{ env.HOST }}
          username: ${{ env.SSH_USER }}
          key: ${{ env.SSH_KEY }}
          port: ${{ env.SSH_PORT }}
          timeout: 120s
          command_timeout: 15m
          envs: NEXTAUTH_SECRET,DATABASE_URL,OPENAI_API_KEY,GEMINI_API_KEY,GROQ_API_KEY,GOOGLE_CLOUD_OCR_API_KEY,GOOGLE_CLOUD_API_KEY,GOOGLE_CLIENT_ID,GOOGLE_CLIENT_SECRET,GITHUB_ID,GITHUB_SECRET
          script: |
            set -e
            cd /var/www/naukrimili
            
            echo "‚ö° Starting optimized deployment..."
            
            # Ensure zstd is installed on server
            if ! command -v zstd &> /dev/null; then
              echo "üì¶ Installing zstd on server..."
              if command -v apt-get &> /dev/null; then
                sudo apt-get update -qq && sudo apt-get install -y zstd
              elif command -v yum &> /dev/null; then
                sudo yum install -y zstd
              elif command -v apk &> /dev/null; then
                sudo apk add zstd
              else
                echo "‚ö†Ô∏è  Could not install zstd automatically. Please install it manually."
              fi
            fi
            
            # Extract deployment bundle
            echo "üì¶ Extracting deployment bundle..."
            if command -v zstd &> /dev/null; then
              tar -I 'zstd -d --threads=0' -xf release.tar.zst 2>&1 | grep -E "(deploy/|extracting)" | head -20 || \
              { echo "‚ö†Ô∏è Extraction taking longer than expected, continuing..."; tar -I 'zstd -d --threads=0' -xf release.tar.zst; }
            else
              echo "‚ùå zstd not found. Cannot extract bundle."
              exit 1
            fi
            
            # Move to production location
            echo "üöÄ Installing new version..."
            rm -rf .next node_modules
            mv deploy/.next deploy/node_modules deploy/package.json deploy/ecosystem.config.cjs \
               deploy/next.config.mjs deploy/server.cjs deploy/prisma deploy/public . 2>/dev/null || true
            # Copy scripts directory if it exists
            if [ -d "deploy/scripts" ]; then
              mkdir -p scripts
              cp -r deploy/scripts/* scripts/ 2>/dev/null || true
            fi
            
            # Cleanup
            rm -rf deploy release.tar.zst .next.backup
            
            # Set environment
            export NODE_ENV=production
            export NEXTAUTH_SECRET="$NEXTAUTH_SECRET"
            export NEXTAUTH_URL="https://naukrimili.com"
            export NEXT_PUBLIC_APP_URL="https://naukrimili.com"
            export DATABASE_URL="$DATABASE_URL"
            export NEXT_TELEMETRY_DISABLED=1
            # API Keys for runtime
            export OPENAI_API_KEY="$OPENAI_API_KEY"
            export GEMINI_API_KEY="$GEMINI_API_KEY"
            export GROQ_API_KEY="$GROQ_API_KEY"
            export GOOGLE_CLOUD_OCR_API_KEY="$GOOGLE_CLOUD_OCR_API_KEY"
            export GOOGLE_CLOUD_API_KEY="$GOOGLE_CLOUD_API_KEY"
            # OAuth Credentials for Google/GitHub Sign-in
            export GOOGLE_CLIENT_ID="$GOOGLE_CLIENT_ID"
            export GOOGLE_CLIENT_SECRET="$GOOGLE_CLIENT_SECRET"
            export GITHUB_ID="$GITHUB_ID"
            export GITHUB_SECRET="$GITHUB_SECRET"
            
            # CRITICAL: Persist OAuth credentials to .env file for ecosystem.config.cjs
            echo "üìù Updating .env file with OAuth credentials..."
            if [ -f .env ]; then
              # Remove existing OAuth credentials if present
              sed -i '/^GOOGLE_CLIENT_ID=/d' .env
              sed -i '/^GOOGLE_CLIENT_SECRET=/d' .env
              sed -i '/^GITHUB_ID=/d' .env
              sed -i '/^GITHUB_SECRET=/d' .env
            else
              touch .env
            fi
            # Append OAuth credentials to .env file
            echo "GOOGLE_CLIENT_ID=$GOOGLE_CLIENT_ID" >> .env
            echo "GOOGLE_CLIENT_SECRET=$GOOGLE_CLIENT_SECRET" >> .env
            echo "GITHUB_ID=$GITHUB_ID" >> .env
            echo "GITHUB_SECRET=$GITHUB_SECRET" >> .env
            echo "‚úÖ OAuth credentials written to .env file"
            
            # Verify DATABASE_URL is set
            echo "üîç Checking DATABASE_URL..."
            if [ -z "$DATABASE_URL" ]; then
              echo "‚ùå FATAL: DATABASE_URL environment variable is not set"
              echo "   Please ensure DATABASE_URL secret is configured in GitHub Actions"
              echo "   Check GitHub Secrets: Settings > Secrets and variables > Actions > DATABASE_URL"
              exit 1
            fi
            
            # Clean DATABASE_URL (strip whitespace and quotes that might come from GitHub Secrets)
            ORIGINAL_DATABASE_URL="$DATABASE_URL"
            DATABASE_URL=$(echo "$DATABASE_URL" | sed 's/^["'\'' ]*//; s/["'\'' ]*$//' | xargs)
            export DATABASE_URL
            
            # Show first part of DATABASE_URL for debugging (masked, after cleaning)
            DATABASE_URL_MASKED=$(echo "$DATABASE_URL" | sed 's/:[^@]*@/:***@/')
            echo "   DATABASE_URL is set: ${DATABASE_URL_MASKED:0:60}..."
            echo "   Length: ${#DATABASE_URL} characters"
            echo "   First 20 chars: '${DATABASE_URL:0:20}'"
            
            # Check if it starts with the correct protocol
            if ! echo "$DATABASE_URL" | grep -qE "^postgresql://|^postgres://"; then
              echo "‚ùå FATAL: Invalid DATABASE_URL format"
              echo ""
              echo "   Expected format: postgresql://user:password@host:port/database"
              echo "   OR: postgres://user:password@host:port/database"
              echo ""
              echo "   Current value (first 80 chars, masked):"
              echo "   ${DATABASE_URL_MASKED:0:80}"
              echo ""
              echo "   Raw value (first 80 chars, showing for debugging):"
              if [ ${#DATABASE_URL} -gt 80 ]; then
                echo "   ${DATABASE_URL:0:80}..."
              else
                echo "   $DATABASE_URL"
              fi
              echo ""
              echo "   First 20 characters: '${DATABASE_URL:0:20}'"
              echo "   Does it start with 'postgresql://' or 'postgres://'? $(echo "$DATABASE_URL" | grep -qE '^postgresql://|^postgres://' && echo 'YES' || echo 'NO')"
              echo ""
              echo "   üîß SOLUTION:"
              echo "   1. Go to: Settings > Secrets and variables > Actions"
              echo "   2. Find 'DATABASE_URL' secret"
              echo "   3. Verify it starts with 'postgresql://' or 'postgres://'"
              echo "   4. If it has quotes, remove them (GitHub Secrets should not have quotes)"
              exit 1
            fi
            
            echo "   ‚úÖ DATABASE_URL format is valid"
            
            # OPTIMIZED: Prepare DATABASE_URL once (convert localhost + add timeouts)
            echo "üîß Preparing DATABASE_URL for database operations..."
            ENHANCED_DATABASE_URL="$DATABASE_URL"
            # Convert localhost to 127.0.0.1 to avoid IPv6 issues (do this once)
            if echo "$ENHANCED_DATABASE_URL" | grep -q "@localhost:"; then
              echo "  Converting 'localhost' to '127.0.0.1' to avoid IPv6 issues"
              ENHANCED_DATABASE_URL=$(echo "$ENHANCED_DATABASE_URL" | sed 's/@localhost:/@127.0.0.1:/g')
            fi
            # Add connection timeout parameters to fail fast
            if echo "$ENHANCED_DATABASE_URL" | grep -qv "connect_timeout"; then
              SEPARATOR=$([ "${ENHANCED_DATABASE_URL#*?}" != "$ENHANCED_DATABASE_URL" ] && echo "&" || echo "?")
              ENHANCED_DATABASE_URL="${ENHANCED_DATABASE_URL}${SEPARATOR}connect_timeout=5&pool_timeout=5"
            fi
            export DATABASE_URL="$ENHANCED_DATABASE_URL"
            echo "  ‚úÖ DATABASE_URL prepared: ${DATABASE_URL//:*@/:***@}"
            
            # Initialize database (create user and database if needed)
            echo "üóÑÔ∏è Initializing database..."
            if [ -f "scripts/init-database.sh" ]; then
              chmod +x scripts/init-database.sh
              echo "  Running init-database.sh script..."
              INIT_OUTPUT=$(bash scripts/init-database.sh 2>&1)
              INIT_EXIT=$?
              
              if [ $INIT_EXIT -ne 0 ]; then
                echo "‚ùå Database initialization failed with exit code: $INIT_EXIT"
                echo "$INIT_OUTPUT" | tail -30
                echo ""
                echo "üìã To fix: Connect to PostgreSQL as superuser and create user/database"
                echo "   Extract from DATABASE_URL: ${DATABASE_URL//:*@/:***@}"
                exit $INIT_EXIT
              fi
              echo "‚úÖ Database initialization completed"
              echo "$INIT_OUTPUT" | grep -E "‚úÖ|‚ùå" | head -10 || true
            else
              echo "‚ö†Ô∏è  init-database.sh not found, skipping user/database creation"
            fi
            
            # Run database migrations
            echo "üîÑ Running database migrations..."
            if [ -d "prisma" ]; then
              echo "  Generating Prisma client..."
              npx prisma generate --schema=./prisma/schema.prisma 2>&1 | grep -E "(Generated|Error)" || true
              
              # Single connection test (removed duplicate - init-database.sh already verified)
              echo "  Verifying database connection..."
              if ! timeout 8 npx prisma db execute --stdin --schema=./prisma/schema.prisma <<< "SELECT 1;" > /dev/null 2>&1; then
                echo "‚ùå Database connection failed!"
                CONN_OUTPUT=$(timeout 8 npx prisma db execute --stdin --schema=./prisma/schema.prisma <<< "SELECT 1;" 2>&1 || true)
                echo "$CONN_OUTPUT" | head -5
                if echo "$CONN_OUTPUT" | grep -qi "FATAL.*role.*does not exist"; then
                  echo "   ERROR: Database user does not exist - check init-database.sh output above"
                fi
                exit 1
              fi
              echo "  ‚úÖ Connection verified"
              
              # Run migrations (idempotent and safe)
              echo "  Deploying migrations..."
              export PRISMA_CLI_QUERY_ENGINE_TYPE=binary
              if timeout 30 npx prisma migrate deploy --schema=./prisma/schema.prisma 2>&1 | tee /tmp/migration.log; then
                echo "‚úÖ Migrations deployed successfully"
              else
                MIGRATION_OUTPUT=$(cat /tmp/migration.log 2>/dev/null || echo "")
                
                # Handle common errors
                if echo "$MIGRATION_OUTPUT" | grep -q "relation.*already exists\|P3018\|42P07"; then
                  CONFLICT_MIGRATION=$(echo "$MIGRATION_OUTPUT" | grep -oP "migration '[^']+'" | head -1 | sed "s/migration '//; s/'//" || echo "")
                  if [ -n "$CONFLICT_MIGRATION" ] && timeout 10 npx prisma migrate resolve --applied "$CONFLICT_MIGRATION" --schema=./prisma/schema.prisma 2>&1; then
                    echo "  ‚úÖ Resolved conflict, retrying..."
                    timeout 30 npx prisma migrate deploy --schema=./prisma/schema.prisma 2>&1 || {
                      echo "‚ùå Migration still failed after conflict resolution"
                      exit 1
                    }
                  else
                    echo "‚ùå Migration conflict - manual resolution needed"
                    echo "$MIGRATION_OUTPUT" | grep -E "relation|already exists|P3018" | head -3
                    exit 1
                  fi
                elif echo "$MIGRATION_OUTPUT" | grep -qi "FATAL.*role.*does not exist"; then
                  echo "‚ùå Database user does not exist!"
                  echo "$MIGRATION_OUTPUT" | grep -i "FATAL.*role\|does not exist" | head -3
                  echo "   Check init-database.sh output above"
                  exit 1
                else
                  echo "‚ùå Migration failed:"
                  echo "$MIGRATION_OUTPUT" | tail -15
                  exit 1
                fi
              fi
              echo "‚úÖ Database migrations complete"
            else
              echo "‚ö†Ô∏è No prisma directory found, skipping migrations"
            fi
            
            # Simplified zero-downtime deployment
            echo "üîÑ Deploying application..."
            mkdir -p ./logs
            
            # Helper function to check for database errors in PM2 logs
            check_db_errors() {
              ERR_LOGS=$(pm2 logs naukrimili --err --lines 15 --nostream 2>/dev/null | tail -10 || echo "")
              if echo "$ERR_LOGS" | grep -qi "FATAL.*role\|does not exist.*role"; then
                echo "  ‚ùå Database errors detected!"
                echo "$ERR_LOGS" | grep -i "FATAL.*role\|does not exist.*role" | head -3
                return 1
              fi
              return 0
            }
            
            # Determine deployment mode and wait time
            if pm2 list | grep -q "naukrimili"; then
              echo "  Using graceful reload (zero-downtime)..."
              pm2 reload naukrimili --update-env --wait-ready
              MAX_WAIT=30
            else
              echo "  Starting fresh..."
              pm2 start ecosystem.config.cjs --env production --update-env
              MAX_WAIT=35
            fi
            
            # Unified wait logic (simplified)
            echo "  Waiting for app to start (up to ${MAX_WAIT}s)..."
            READY=false
            i=0
            while [ $i -lt $MAX_WAIT ]; do
              i=$((i + 1))
              
              # Check PM2 status and health endpoint
              if pm2 list | grep -q "naukrimili.*online"; then
                if curl -sf --max-time 2 http://127.0.0.1:3000/api/health > /dev/null 2>&1 || \
                   curl -sf --max-time 2 http://localhost:3000/api/health > /dev/null 2>&1; then
                  READY=true
                  echo "  ‚úÖ App is ready (after ${i}s)"
                  break
                fi
              fi
              
              # Check for errors every 5 seconds
              if [ $((i % 5)) -eq 0 ]; then
                if ! check_db_errors; then
                  pm2 status
                  exit 1
                fi
                if [ $i -lt $MAX_WAIT ]; then
                  echo "  Still starting... (${i}/${MAX_WAIT}s)"
                fi
              fi
              
              sleep 1
            done
            
            # Final check
            if [ "$READY" = true ]; then
              echo "‚úÖ Deployment successful"
              pm2 save
              exit 0
            else
              echo "‚ö†Ô∏è  App not fully ready, but checking status..."
              pm2 status
              if ! check_db_errors; then
                exit 1
              fi
              echo "‚ö†Ô∏è  Health check timed out, but no errors detected - proceeding"
              pm2 save
              exit 0
            fi
